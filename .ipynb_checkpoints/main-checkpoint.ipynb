{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744f6346",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e5341",
   "metadata": {},
   "source": [
    "This Notebook is a step for step handbook for getting per Unit Generation Data out of the Smard Data. It isn't necessary to run this notebook, the processed data can also be downloaded directly from the repository. This is just for understanding how the data was processed.\n",
    "\n",
    "As Data Source the Smard Powerplant Data was used and processed so it can be handled with the EIC IDs of each Unit.\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19273fe",
   "metadata": {},
   "source": [
    "## Preparation of Python environment\n",
    "\n",
    "The following modules and their dependencies are required to run this notebook:\n",
    "* Pandas (with openpyxl)\n",
    "* Numpy\n",
    "* datetime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571166f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "import os\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635cbc8",
   "metadata": {},
   "source": [
    "## Download of input files and setup of folder structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a165f278",
   "metadata": {},
   "source": [
    "First the raw primary Data was downloaded and prepared. Two different Datasets were used\n",
    "\n",
    "- First the _blocks.xlsx_ data, which is a list of all powerplants in Germany. It was collected by the INATECH and is available via the repository.\n",
    "\n",
    "- For the generation data csv-files were downloaded from the Smard Website:\n",
    "https://www.smard.de/en/downloadcenter/download-power-plant-data/?downloadAttributes=%7B%22selectedPowerPlant%22:%22all%22,%22selectedContent%22:%22generation%22,%22from%22:1451602800000,%22to%22:1483225199999,%22selectedFileType%22:%22CSV%22%7D\n",
    "It was downloaded for each year independently from year 2016 to 2021. For that following options were selected:\n",
    "    - _All Power Plants_\n",
    "    - _Content: Actual generation_\n",
    "    - _01.01.Year - 31.12.Year_ where you choose for year each year from 2016-2021\n",
    "    - _Select resolution: original resolution_\n",
    "    - _CSV_\n",
    "\n",
    " Then each csv file was put into the _smard_ folder (without a Subfolder). So in the end all csv files are in the __smard__ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b013bff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ETS-ID</th>\n",
       "      <th>EIC</th>\n",
       "      <th>Name BNA</th>\n",
       "      <th>City</th>\n",
       "      <th>Plant name</th>\n",
       "      <th>Block name</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Column_Block_Smard</th>\n",
       "      <th>Column_Block_Smard_2</th>\n",
       "      <th>Column_Block_Smard_Alternative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>11WD8SCHW5X---19</td>\n",
       "      <td>1MKA</td>\n",
       "      <td>Schwedt</td>\n",
       "      <td>IKS PCK Schwedt</td>\n",
       "      <td>1</td>\n",
       "      <td>IKS_PCK_Schwedt</td>\n",
       "      <td>Generation_DE 1MKA [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>11WD8SCHW5X---27</td>\n",
       "      <td>2MKA</td>\n",
       "      <td>Schwedt</td>\n",
       "      <td>IKS PCK Schwedt</td>\n",
       "      <td>2</td>\n",
       "      <td>IKS_PCK_Schwedt</td>\n",
       "      <td>Generation_DE 2MKA [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1399</td>\n",
       "      <td>11WD7BERG1S--A-X</td>\n",
       "      <td>Bergkamen A</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>A</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Generation_DE Bergkamen A [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>852</td>\n",
       "      <td>11WD7MITB1C---A1</td>\n",
       "      <td>Bexbach</td>\n",
       "      <td>Bexbach</td>\n",
       "      <td>Bexbach</td>\n",
       "      <td>A</td>\n",
       "      <td>Kraftwerk_Bexbach</td>\n",
       "      <td>Generation_DE Bexbach [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1453</td>\n",
       "      <td>11WD8BOXB1L---N8</td>\n",
       "      <td>Boxberg Block N</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>N</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Generation_DE Boxberg Block N [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1453</td>\n",
       "      <td>11WD8BOXB1L---P4</td>\n",
       "      <td>Boxberg Block P</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>P</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Generation_DE Boxberg Block P [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1454</td>\n",
       "      <td>11WD8BOXB1L---Q2</td>\n",
       "      <td>Boxberg Block Q</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Q</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Generation_DE Boxberg Block Q [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1454</td>\n",
       "      <td>11WD8BOXB1L---R0</td>\n",
       "      <td>Boxberg Block R</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>R</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Generation_DE Boxberg Block R [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1419</td>\n",
       "      <td>11WD2BUSD0000386</td>\n",
       "      <td>Buschhaus</td>\n",
       "      <td>Helmstedt</td>\n",
       "      <td>Buschhaus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buschhaus</td>\n",
       "      <td>Generation_DE D [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1409</td>\n",
       "      <td>11WD7HERD2G-H6-X</td>\n",
       "      <td>Cuno Heizkraftwerk Herdecke H6</td>\n",
       "      <td>Herdecke</td>\n",
       "      <td>Cuno HKW Herdecke</td>\n",
       "      <td>H6</td>\n",
       "      <td>Cuno_Heizkraftwerk_Herdecke</td>\n",
       "      <td>Generation_DE Cuno Heizkraftwerk Herdecke H6 [MW]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ETS-ID               EIC                        Name BNA       City  \\\n",
       "0      19  11WD8SCHW5X---19                            1MKA    Schwedt   \n",
       "1      19  11WD8SCHW5X---27                            2MKA    Schwedt   \n",
       "2    1399  11WD7BERG1S--A-X                     Bergkamen A  Bergkamen   \n",
       "3     852  11WD7MITB1C---A1                         Bexbach    Bexbach   \n",
       "4    1453  11WD8BOXB1L---N8                 Boxberg Block N    Boxberg   \n",
       "5    1453  11WD8BOXB1L---P4                 Boxberg Block P    Boxberg   \n",
       "6    1454  11WD8BOXB1L---Q2                 Boxberg Block Q    Boxberg   \n",
       "7    1454  11WD8BOXB1L---R0                 Boxberg Block R    Boxberg   \n",
       "8    1419  11WD2BUSD0000386                       Buschhaus  Helmstedt   \n",
       "9    1409  11WD7HERD2G-H6-X  Cuno Heizkraftwerk Herdecke H6   Herdecke   \n",
       "\n",
       "          Plant name Block name                     Filename  \\\n",
       "0    IKS PCK Schwedt          1              IKS_PCK_Schwedt   \n",
       "1    IKS PCK Schwedt          2              IKS_PCK_Schwedt   \n",
       "2          Bergkamen          A                    Bergkamen   \n",
       "3            Bexbach          A            Kraftwerk_Bexbach   \n",
       "4            Boxberg          N                      Boxberg   \n",
       "5            Boxberg          P                      Boxberg   \n",
       "6            Boxberg          Q                      Boxberg   \n",
       "7            Boxberg          R                      Boxberg   \n",
       "8          Buschhaus        NaN                    Buschhaus   \n",
       "9  Cuno HKW Herdecke         H6  Cuno_Heizkraftwerk_Herdecke   \n",
       "\n",
       "                                  Column_Block_Smard Column_Block_Smard_2  \\\n",
       "0                            Generation_DE 1MKA [MW]                  NaN   \n",
       "1                            Generation_DE 2MKA [MW]                  NaN   \n",
       "2                     Generation_DE Bergkamen A [MW]                  NaN   \n",
       "3                         Generation_DE Bexbach [MW]                  NaN   \n",
       "4                 Generation_DE Boxberg Block N [MW]                  NaN   \n",
       "5                 Generation_DE Boxberg Block P [MW]                  NaN   \n",
       "6                 Generation_DE Boxberg Block Q [MW]                  NaN   \n",
       "7                 Generation_DE Boxberg Block R [MW]                  NaN   \n",
       "8                               Generation_DE D [MW]                  NaN   \n",
       "9  Generation_DE Cuno Heizkraftwerk Herdecke H6 [MW]                  NaN   \n",
       "\n",
       "  Column_Block_Smard_Alternative  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  \n",
       "5                            NaN  \n",
       "6                            NaN  \n",
       "7                            NaN  \n",
       "8                            NaN  \n",
       "9                            NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIAL SETUP\n",
    "\n",
    "# data is currently provided for the years of 2016 to 2022\n",
    "years = [2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
    "\n",
    "# import main file for German powerplant data including EIC, ETS-ID, electrical and heat power, CHP\n",
    "blocks = read_excel('input/blocks.xlsx')\n",
    "\n",
    "blocks.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfee7a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATION OF EIC AND ETS-ID LISTS\n",
    "\n",
    "# list of all powerplant block EIC codes\n",
    "eic_list = blocks['EIC'].unique()\n",
    "\n",
    "# list of all powerplant location ETS-ID codes\n",
    "ets_list = blocks['ETS-ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f14c2",
   "metadata": {},
   "source": [
    "### Prepare the smard data\n",
    "In the smard data we have a csv-file for each powerplant and year. We generate a Dataframe which maps \n",
    "the files to the correct plant name. This plant name is also present in the column _filename_ in the _blocks.xlsx_ data.\n",
    "\n",
    "With this way we can map the blocks represented in the _blocks.xlsx_ to the correct csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c882189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>plant name</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_201601010000_201612312359_hour_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_201701010000_201712312359_stunde_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_201801010000_201812312359_stunde_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_201901010000_201912312359_stunde_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_202001010000_202012312359_stunde_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_202101010000_202112312359_hour_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bergkamen</td>\n",
       "      <td>Bergkamen_202201010000_202212312359_stunde_6.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg_201601010000_201612312359_hour_8.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg_201701010000_201712312359_stunde_8.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>Boxberg</td>\n",
       "      <td>Boxberg_201801010000_201812312359_stunde_8.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year plant name                                          filename\n",
       "0  2016  Bergkamen    Bergkamen_201601010000_201612312359_hour_6.csv\n",
       "1  2017  Bergkamen  Bergkamen_201701010000_201712312359_stunde_6.csv\n",
       "2  2018  Bergkamen  Bergkamen_201801010000_201812312359_stunde_6.csv\n",
       "3  2019  Bergkamen  Bergkamen_201901010000_201912312359_stunde_6.csv\n",
       "4  2020  Bergkamen  Bergkamen_202001010000_202012312359_stunde_6.csv\n",
       "5  2021  Bergkamen    Bergkamen_202101010000_202112312359_hour_6.csv\n",
       "6  2022  Bergkamen  Bergkamen_202201010000_202212312359_stunde_6.csv\n",
       "7  2016    Boxberg      Boxberg_201601010000_201612312359_hour_8.csv\n",
       "8  2017    Boxberg    Boxberg_201701010000_201712312359_stunde_8.csv\n",
       "9  2018    Boxberg    Boxberg_201801010000_201812312359_stunde_8.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GENERATE MAPPING FROM CSV FILE TO BLOCK\n",
    "\n",
    "# Folder which contains all smard data files\n",
    "smard_folder = \"./input/smard\"\n",
    "files_smard = os.listdir(smard_folder)\n",
    "\n",
    "# Initialize columns for DataFrame, in which we save the year, the plant name and the filename\n",
    "years_smard = []\n",
    "plant_names_smard = []\n",
    "filenames_smard = []\n",
    "\n",
    "# Loop through all filenames\n",
    "for filename in files_smard:\n",
    "    # Split the filename on underscore, to get each information saved in the filename\n",
    "    filename_array = filename.split(\"_\")\n",
    "    \n",
    "    # Check if file is csv file\n",
    "    if filename_array[-1].split(\".\")[1] != \"csv\":\n",
    "        continue\n",
    "    \n",
    "    # Get plant name out of the filename\n",
    "    plant_name = \"_\".join(filename_array[:-4])\n",
    "    \n",
    "    # Check if Plant name is in the blocks.xlsx file, if not continue\n",
    "    if  plant_name not in blocks[\"Filename\"].values:\n",
    "        continue\n",
    "\n",
    "    # Save variables in the corresponding array\n",
    "    filenames_smard.append(filename)\n",
    "    years_smard.append(filename_array[-3][:4])\n",
    "    plant_names_smard.append(plant_name)\n",
    "\n",
    "# Convert everything to a DataFrame\n",
    "smard_files_df = pd.DataFrame({\"year\":years_smard, \"plant name\":plant_names_smard, \"filename\":filenames_smard}) \n",
    "\n",
    "smard_files_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84a522",
   "metadata": {},
   "source": [
    "### Define helper functions for processing of Smard Data\n",
    "\n",
    "In the following we define function we use for the processing:\n",
    "1. __rename_column__: This function is used in the pd.DataFrame.apply function and get's rid of the Ending at each column, because it differs from year to year (Originalauflösung or original resolution) \n",
    "\n",
    "1. __rename_columns__: This function is used to rename the columns in the csv files, so they match with the column names saved in the smard_files_df. Therefore we first iterate over each column and rename it with the function described above\n",
    "\n",
    "1. __to_datetime__: This function converts the Time Format given in the SMARD Data to a Datetime Format\n",
    "\n",
    "1. __process_dataframe__: This function processes the Data for one Generation unit, where it does the following: \n",
    "    - Change Datatype of Dataframe to numeric\n",
    "    - use to_datetime function to get correct timestamps \n",
    "    - renames the column from the _eic-id_ to _Generation [MW]_ \n",
    "    - fills up missing timestamps with NaN so every EIC-ID has 8760 (8784) rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c70b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_column(column_name):\n",
    "    # Split the name by \" \"\n",
    "    column_name_split = column_name.split(\" \")\n",
    "\n",
    "    # Get the index of \"[MW]\", as this is in each column of every file\n",
    "    index_mw = column_name_split.index(\"[MW]\")\n",
    "\n",
    "    # join again but only including until \"[MW]\" \n",
    "    column_name_new = \" \".join(column_name_split[:index_mw+1])\n",
    "    \n",
    "    return column_name_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9c8ec83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(smard_data_df):\n",
    "    \n",
    "    # Rename Columns so they can be matched to the entries in the Blocks Dataset\n",
    "    smard_data_df = smard_data_df.rename(lambda x: rename_column(x) if \"[MW]\" in x else x, axis=1)\n",
    "\n",
    "    # Rename First 3 Columns so all are named the same\n",
    "    new_column_names = [\"date\", \"start\", \"end\"]\n",
    "    for i in range(3): smard_data_df.columns.values[i] = new_column_names[i]\n",
    "\n",
    "    return smard_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3303c3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the Time Format given in the SMARD Data to a Datetime Format\n",
    "def to_datetime(x):\n",
    "    \n",
    "    # Extract Date from Dataframe\n",
    "    date = str(x[\"date\"])\n",
    "    date_len = len(date)\n",
    "    if  date_len == 8 or date_len == 7:\n",
    "        year = int(date[-4:])\n",
    "        month = int(date[-6:-4])\n",
    "        day = int(date[:-6])\n",
    "    else:\n",
    "        #day, month, year = date.split(\".\") \n",
    "        print(blocks[blocks[\"EIC\"] == x[\"EIC-ID\"]][\"Name BNA\"].values[0])\n",
    "        return False\n",
    "                \n",
    "        \n",
    "    # Get hour from x\n",
    "    hour = int(x[1].split(\":\")[0])\n",
    "    x_date = datetime.datetime(year=year, month=month, day=day, hour=hour)\n",
    "    return x_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a2dfd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the Data for one Generation unit\n",
    "def process_dataframe(smard_data_df, eic_id, year):\n",
    "\n",
    "    # Change Datatype of column to be able to handle data as numbers\n",
    "    smard_data_df[eic_id] = pd.to_numeric(smard_data_df[eic_id], errors=\"coerce\")\n",
    "\n",
    "    # Add Column Timestamp, which hase the Starting hour of the slot as a Datetime Format\n",
    "    smard_data_df[\"Timestamp\"] = smard_data_df.apply(to_datetime, axis=1)\n",
    "\n",
    "    # Copy the Columns Timestamp, EIC-ID, from the current DataFrame, which will be in the output Dataframe\n",
    "    smard_data_long_df = smard_data_df[[\"Timestamp\", eic_id]].copy()\n",
    "\n",
    "    # Rename the Column {eic_id} to Generation, because this contains the Generation Data\n",
    "    smard_data_long_df = smard_data_long_df.rename(columns={eic_id: \"Generation [MW]\"})\n",
    "\n",
    "    # Fill up missing rows with NaNs, so each Generation Unit has a row for each hour\n",
    "    new_index = pd.Series(pd.date_range(start=f'{year}-01-01', end=f'{year}-12-31 23:00:00', freq='H'))\n",
    "    smard_data_long_df = smard_data_long_df.drop_duplicates([\"Timestamp\"], keep=\"first\")\n",
    "    smard_data_long_df = smard_data_long_df.set_index(\"Timestamp\")\n",
    "    smard_data_long_df = smard_data_long_df.reindex(new_index, fill_value=np.nan)\n",
    "\n",
    "    # Add a Column EIC-ID with the eic_id as value\n",
    "    smard_data_long_df[\"EIC-ID\"] = eic_id\n",
    "    \n",
    "    return smard_data_long_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02563fcb",
   "metadata": {},
   "source": [
    "## Process Data for general use\n",
    "Now the final processing is done, where a long csv for each year is generated containing all Generation Data of each Unit.\n",
    "To do that, we loop over all power plants in the smard folder. Then for each file we get the correspoding blocks by mapping the file to the _blocks.xlsx_, as well as the correct filename for power plant and year.\n",
    "\n",
    "Then the file is loaded and the columns are renamed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b4ba8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bergkamen\n",
      "Boxberg\n",
      "Braunkohlekraftwerk_Lippendorf\n",
      "Burghausen_GT\n",
      "Buschhaus\n",
      "Cuno_Heizkraftwerk_Herdecke\n",
      "Datteln\n",
      "Dormagen\n",
      "Duisburg_Hamborn\n",
      "Duisburg_Heizkraftwerk_III\n",
      "Duisburg_Ruhrort\n",
      "E-Werk_Wilhelmshaven\n",
      "Emsland\n",
      "Franken_1\n",
      "Frimmersdorf\n",
      "'EIC-ID'\n",
      "'EIC-ID'\n",
      "Gaskraftwerk_Irsching\n",
      "Gemeinschaftskraftwerk_Kiel\n",
      "Gersteinwerk\n",
      "GKH_St_cken\n",
      "Heizkraftwerk_Altbach_Deizisau\n",
      "Heizkraftwerk_Dresden-Nossener_Br_cke\n",
      "Heizkraftwerk_Heilbronn\n",
      "Heizkraftwerk_Lausward\n",
      "Heizkraftwerk_Leipzig-Nord\n",
      "Heizkraftwerk_Merkenich\n",
      "Heizkraftwerk_M_nchen_S_d_GUD1_\n",
      "Heizkraftwerk_M_nchen_S_d_GUD2\n",
      "Heizkraftwerk_Niehl\n",
      "Heizkraftwerk_R_merbr_cke\n",
      "Heizkraftwerk_West_Wolfsburg\n",
      "Heyden\n",
      "Huckingen\n",
      "Huntorf\n",
      "Ibbenb_ren\n",
      "IKS_PCK_Schwedt\n",
      "Klingenberg\n",
      "Knapsack_Gas_II\n",
      "Knapsack_Gas_I\n",
      "KNG_Kraftwerk_Rostock\n",
      "Kraftwerk_BASF_Ludwigshafen_Mitte\n",
      "Kraftwerk_BASF_Ludwigshafen_S_d\n",
      "Kraftwerk_Bexbach\n",
      "Kraftwerk_Bremer_Hafen\n",
      "Kraftwerk_Farge\n",
      "Kraftwerk_Hastedt\n",
      "Kraftwerk_Herne\n",
      "Kraftwerk_Ingolstadt\n",
      "Kraftwerk_J_nschwalde\n",
      "Kraftwerk_Mainz\n",
      "Kraftwerk_Mittelsb_ren\n",
      "Kraftwerk_Voerde\n",
      "'EIC-ID'\n",
      "'EIC-ID'\n",
      "Kraftwerk_Walheim\n",
      "Kraftwerk_Walsum\n",
      "Kraftwerk_Wilhelmshaven\n",
      "KWH_Hannover\n",
      "KWM_Mehrum\n",
      "K_stenkraftwerk_K.I.E.L.\n",
      "'11W0-0000-0163-M'\n",
      "Lichterfelde\n",
      "Moorburg\n",
      "M_nchen_Nord_2\n",
      "Neurath\n",
      "Niederau_em\n",
      "Reuter\n",
      "Reuter_West\n",
      "Rheinhafen-Dampfkraftwerk\n",
      "Schkopau\n",
      "Scholven\n",
      "Schwarze_Pumpe\n",
      "Staudinger\n",
      "Tiefstack\n",
      "Trianel_Gaskraftwerk_\n",
      "Trianel_Kohlekraftwerk_L_nen\n",
      "V_lklingen\n",
      "Wedel\n",
      "Weiher\n",
      "Weisweiler\n",
      "Westfalen\n",
      "Zolling\n",
      "Bergkamen\n",
      "Boxberg\n",
      "Braunkohlekraftwerk_Lippendorf\n",
      "Burghausen_GT\n",
      "Buschhaus\n",
      "Cuno_Heizkraftwerk_Herdecke\n",
      "Datteln\n",
      "Dormagen\n",
      "Duisburg_Hamborn\n",
      "Duisburg_Heizkraftwerk_III\n",
      "Duisburg_Ruhrort\n",
      "E-Werk_Wilhelmshaven\n",
      "Emsland\n",
      "Franken_1\n",
      "Frimmersdorf\n",
      "'EIC-ID'\n",
      "'EIC-ID'\n",
      "Gaskraftwerk_Irsching\n",
      "Gemeinschaftskraftwerk_Kiel\n",
      "Gersteinwerk\n",
      "GKH_St_cken\n",
      "Heizkraftwerk_Altbach_Deizisau\n",
      "Heizkraftwerk_Dresden-Nossener_Br_cke\n",
      "Heizkraftwerk_Heilbronn\n",
      "Heizkraftwerk_Lausward\n",
      "Heizkraftwerk_Leipzig-Nord\n",
      "Heizkraftwerk_Merkenich\n",
      "Heizkraftwerk_M_nchen_S_d_GUD1_\n",
      "Heizkraftwerk_M_nchen_S_d_GUD2\n",
      "Heizkraftwerk_Niehl\n",
      "Heizkraftwerk_R_merbr_cke\n",
      "Heizkraftwerk_West_Wolfsburg\n",
      "Heyden\n",
      "Huckingen\n",
      "Huntorf\n",
      "Ibbenb_ren\n",
      "IKS_PCK_Schwedt\n",
      "Klingenberg\n",
      "Knapsack_Gas_II\n",
      "Knapsack_Gas_I\n",
      "KNG_Kraftwerk_Rostock\n",
      "Kraftwerk_BASF_Ludwigshafen_Mitte\n",
      "Kraftwerk_BASF_Ludwigshafen_S_d\n",
      "Kraftwerk_Bexbach\n",
      "Kraftwerk_Bremer_Hafen\n",
      "Kraftwerk_Farge\n",
      "Kraftwerk_Hastedt\n",
      "Kraftwerk_Herne\n",
      "Kraftwerk_Ingolstadt\n",
      "Kraftwerk_J_nschwalde\n",
      "Kraftwerk_Mainz\n",
      "Kraftwerk_Mittelsb_ren\n",
      "Kraftwerk_Voerde\n",
      "'EIC-ID'\n",
      "'EIC-ID'\n",
      "Kraftwerk_Walheim\n",
      "Kraftwerk_Walsum\n",
      "Kraftwerk_Wilhelmshaven\n",
      "'EIC-ID'\n",
      "KWH_Hannover\n",
      "KWM_Mehrum\n",
      "K_stenkraftwerk_K.I.E.L.\n",
      "'11W0-0000-0163-M'\n",
      "Lichterfelde\n",
      "Moorburg\n",
      "M_nchen_Nord_2\n",
      "Neurath\n",
      "Niederau_em\n",
      "Reuter\n",
      "Reuter_West\n",
      "Rheinhafen-Dampfkraftwerk\n",
      "Schkopau\n",
      "Scholven\n",
      "Schwarze_Pumpe\n",
      "Staudinger\n",
      "Tiefstack\n",
      "Trianel_Gaskraftwerk_\n",
      "Trianel_Kohlekraftwerk_L_nen\n",
      "V_lklingen\n",
      "Wedel\n",
      "Weiher\n",
      "Weisweiler\n",
      "Westfalen\n",
      "Zolling\n"
     ]
    }
   ],
   "source": [
    "# Loop over years to get Generation Data for each year\n",
    "years = [2018, 2019, 2020, 2021, 2022]\n",
    "for year in years:\n",
    "\n",
    "    # Initialize the Dataframe\n",
    "    generation_data_long_df = pd.DataFrame(data=[], columns=[\"EIC-ID\", \"Generation [MW]\"])\n",
    "    \n",
    "    # Loop over each Power Plant listed as CSV-File, get the smard Data and calculate the yearly Generation Data\n",
    "    for smard_file in smard_files_df[\"plant name\"].unique():\n",
    "        \n",
    "        print(smard_file)\n",
    "\n",
    "        # Get all Blocks belonging to one CSV-File\n",
    "        blocks_file_df = blocks[blocks[\"Filename\"] == smard_file]\n",
    "\n",
    "        # Check if DataFrame is emtpty\n",
    "        if len(blocks_file_df) == 0:\n",
    "            continue\n",
    "\n",
    "        # Get the Plant Name and corresponding column names\n",
    "        plant_name = blocks_file_df[\"Plant name\"].values[0]\n",
    "        column_names = blocks_file_df[\"Column_Block_Smard\"].unique()        \n",
    "        \n",
    "\n",
    "        # With the Plant Name get the correct csv-filename for each Year\n",
    "        filename = smard_files_df[(smard_files_df[\"plant name\"] == smard_file) & (smard_files_df[\"year\"] == str(year))][\"filename\"].values\n",
    "        \n",
    "        # Check if a filename was found, if not throw an Error and continue\n",
    "        if len(filename) == 0: \n",
    "            bna_name = blocks_file_df[\"Name BNA\"].values\n",
    "            print(f\"WARNING: No CSV Filename found for {bna_name} in year {year}\")\n",
    "            continue\n",
    "        filename = filename[0]\n",
    "\n",
    "        # Load CSV File\n",
    "        smard_data_df = read_csv(f\"{smard_folder}/{filename}\", sep=\";\", decimal=\",\", thousands=\".\", na_values=[\"-\"])\n",
    "\n",
    "        # Use function above to rename the columns \n",
    "        smard_data_df = rename_columns(smard_data_df)\n",
    "\n",
    "        # Loop over all Blocks belonging to the csv file which are defined in the blocks dataset\n",
    "        for column_name in column_names:\n",
    "\n",
    "            # Boolean to handle multiple columns\n",
    "            multiple_columns = False\n",
    "\n",
    "            # Get EIC Ids of the Column name\n",
    "            eic_ids_column = blocks_file_df[blocks_file_df[\"Column_Block_Smard\"]== column_name][\"EIC\"].values\n",
    "\n",
    "            # Check if there is just one Columns for multiple EIC-IDS\n",
    "            # If yes each generation entry in the column will be devided by the amount of different EIC IDS and split into multiple Columns\n",
    "            amt_eic_ids = len(eic_ids_column)\n",
    "            if amt_eic_ids > 1:\n",
    "                multiple_columns = True\n",
    "\n",
    "            # Use Try and Catch to handle multiple column names, as some Blocks are named different in seperate years\n",
    "            try:\n",
    "            # Check if One column represents multiple EIC-IDs\n",
    "                if multiple_columns:\n",
    "\n",
    "                    # Create one new column per EIC-ID, where the EIC ID is the name of the column\n",
    "                    for eic_id in eic_ids_column:\n",
    "\n",
    "                        # Each column get's the equal share of the Values, \n",
    "                        # so they're calculated by dividing the Values in the original column by the amount of EIC-IDs \n",
    "                        smard_data_df[eic_id] = smard_data_df[column_name] / len(eic_ids_column)\n",
    "                        smard_data_long_df = process_dataframe(smard_data_df=smard_data_df, eic_id=eic_id, year=year)\n",
    "\n",
    "                else:\n",
    "                    # If it is just one EIC-ID for that column get the EIC-ID out of the eic_ids_column list\n",
    "                    eic_id = eic_ids_column[0]\n",
    "\n",
    "                    # Check if for one EIC-ID multiple Columns exist to add them up\n",
    "                    column_2 = blocks_file_df[blocks_file_df[\"EIC\"]== eic_id][\"Column_Block_Smard_2\"].values[0]\n",
    "                    if type(column_2) == \"str\":\n",
    "                        smard_data_df[eic_id] = smard_data_df[column_name] + smard_data_df[column_2]\n",
    "                        smard_data_long_df = process_dataframe(smard_data_df=smard_data_df, eic_id=eic_id, year=year)\n",
    "\n",
    "                    else:\n",
    "                        # Rename the columns so the correct column will be changed to EIC-ID as Column name\n",
    "                        smard_data_df.columns = [eic_id if x== column_name else x for x in smard_data_df.columns]\n",
    "                        smard_data_long_df = process_dataframe(smard_data_df=smard_data_df, eic_id=eic_id, year=year)\n",
    "\n",
    "            # Throws error when Column name doesn't exist, then try second column name\n",
    "            except Exception as error:\n",
    "\n",
    "                # Try second Column name, if that also not works continue \n",
    "                try:\n",
    "                    # Get second name of Column in csv File for that Block\n",
    "                    column_name = blocks_file_df[blocks_file_df[\"EIC\"]==eic_id][\"Column_Block_Smard_Alternative\"].values[0]\n",
    "        \n",
    "                    # Rename the columns so the correct column will be changed to EIC-ID as Column name\n",
    "                    smard_data_df.columns = [eic_id if x == column_name else x for x in smard_data_df.columns]\n",
    "                    smard_data_long_df = process_dataframe(smard_data_df=smard_data_df, eic_id=eic_id, year=year)\n",
    "                \n",
    "                except Exception as error:\n",
    "                    print(error)\n",
    "                    continue\n",
    "\n",
    "            # Concat the current Dataframe to the long Dataframe\n",
    "            generation_data_long_df = pd.concat([generation_data_long_df, smard_data_long_df], ignore_index=False)\n",
    "    \n",
    "    # Add a column with BNA Name to the file\n",
    "    generation_data_long_df[\"BNA Name\"] = generation_data_long_df.apply(lambda x: blocks[blocks[\"EIC\"] == x[\"EIC-ID\"]][\"Name BNA\"].values[0], axis=1)\n",
    "    \n",
    "    # Save yearly generation as csv-file\n",
    "    generation_data_long_df.to_csv(f\"output/general/generation_data_long_{year}.csv\")\n",
    "    #generation_data_long_df.to_excel(f\"output/general/generation_data_long_{year}.xlsx\")\n",
    "\n",
    "generation_data_long_df.head(20)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c427b88",
   "metadata": {},
   "source": [
    "## Process Data for use with ETS-IDs \n",
    "\n",
    "With this step the data is processed so it can be easily used with ETS-IDs. Therefore one csv-file for each ETS-ID and year is generated, with the EIC-IDs as columns. \n",
    "\n",
    "So the Matching betweeen EIC-IDs (Generation) and ETS-IDS (Emissions) is already implemented and further data processing ca be done easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b8537f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'contains'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m): smard_data_df_output\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[i] \u001b[38;5;241m=\u001b[39m new_column_names[i]\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Get timestamp by date and time, where the timestamop defines the start time of the hourly generation data\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m smard_data_df_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msmard_data_df_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Set timestamp as index\u001b[39;00m\n\u001b[0;32m    126\u001b[0m smard_data_df_output \u001b[38;5;241m=\u001b[39m smard_data_df_output\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:8839\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8828\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m   8830\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m   8831\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   8832\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8837\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m   8838\u001b[0m )\n\u001b[1;32m-> 8839\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw()\n\u001b[1;32m--> 727\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    850\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m     results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# wrap results\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    865\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m    866\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    868\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    869\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    870\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    871\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m): smard_data_df_output\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mvalues[i] \u001b[38;5;241m=\u001b[39m new_column_names[i]\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# Get timestamp by date and time, where the timestamop defines the start time of the hourly generation data\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m smard_data_df_output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m smard_data_df_output\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Set timestamp as index\u001b[39;00m\n\u001b[0;32m    126\u001b[0m smard_data_df_output \u001b[38;5;241m=\u001b[39m smard_data_df_output\u001b[38;5;241m.\u001b[39mset_index([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      9\u001b[0m     month \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(date[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m])\n\u001b[0;32m     10\u001b[0m     day \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(date[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m6\u001b[39m])\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mdate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     12\u001b[0m     day, month, year \u001b[38;5;241m=\u001b[39m date\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(blocks[blocks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIC\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEIC-ID\u001b[39m\u001b[38;5;124m\"\u001b[39m]][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName BNA\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'contains'"
     ]
    }
   ],
   "source": [
    "# IMPORTING THE GENERATION DATA FROM THE SMARD CSV FILES\n",
    "\n",
    "# The columns we add to the installations_df, for each year a Columns with the Generation per Year\n",
    "columns = [\"EIC\"] + [f'Generation elec. {y} [MWh_el]' for y in years]\n",
    "\n",
    "# Loop over each File in the smard_files Dataframe and calculate the yearly Generation Data\n",
    "for plant_name in smard_files_df[\"plant name\"].unique():\n",
    "\n",
    "    # Get all Blocks belonging to one Plant Name\n",
    "    blocks_smard_df = blocks[blocks[\"Filename\"] == plant_name]\n",
    "\n",
    "    # Check if DataFrame is emtpty\n",
    "    if len(blocks_smard_df) == 0:\n",
    "        continue\n",
    "\n",
    "    # Get all ETS-IDs, mostly it's just one id but for some Plants there is more than one ID\n",
    "    ets_ids_blocks = blocks_smard_df[\"ETS-ID\"].unique()\n",
    "\n",
    "    # Loop over years to get Generation Data for each year\n",
    "    for year in years:\n",
    "\n",
    "        # With the Plant Name get the correct csv-filename for ETS-ID and Year\n",
    "        filename = smard_files_df[(smard_files_df[\"plant name\"] == plant_name) & (smard_files_df[\"year\"] == str(year))][\"filename\"].values\n",
    "        \n",
    "        # Check if a filename was found, if not throw an Error and continue\n",
    "        if len(filename) == 0: \n",
    "            bna_name = blocks_smard_df[\"Name BNA\"].values\n",
    "            print(f\"WARNING: No CSV Filename found for {bna_name} in year {year}\")\n",
    "            continue\n",
    "        filename = filename[0]\n",
    "\n",
    "        # Read in CSV Data\n",
    "        smard_data_df = read_csv(f\"{smard_folder}/{filename}\", delimiter=\";\", thousands=\".\", na_values=\"-\")\n",
    "\n",
    "        # Use function above to rename the columns \n",
    "        smard_data_df = rename_columns(smard_data_df)\n",
    "\n",
    "        # Loop over ETS-IDs to be able to seperate Generation Data into ETS seperated CSV Files\n",
    "        for ets_id in ets_ids_blocks:\n",
    "\n",
    "            # Get the Blocks which have all the same ETS ID out of the Blocks\n",
    "            # with the same filename\n",
    "            blocks_ets_df = blocks_smard_df[blocks_smard_df[\"ETS-ID\"] == ets_id]\n",
    "\n",
    "            # Get the corresponding EIC IDs\n",
    "            eic_ids = blocks_ets_df[\"EIC\"].values\n",
    "\n",
    "            # Get columns Names to be able to handle multiple EICs for one column\n",
    "            column_names = blocks_ets_df[\"Column_Block_Smard\"].unique()\n",
    "\n",
    "            # Loop over all Blocks belonging to the csv file which are defined in th blocks dataset\n",
    "            # and have the same ETS ID\n",
    "            for column_name in column_names:\n",
    "\n",
    "                # Boolean to handle columns with multiple EIC-IDs\n",
    "                multiple_columns = False\n",
    "\n",
    "                # Get EIC Ids of the Column name\n",
    "                eic_ids_column = blocks_ets_df[blocks_ets_df[\"Column_Block_Smard\"] == column_name][\"EIC\"].values\n",
    "\n",
    "                # Check if there is just one Columns for multiple EIC-IDS\n",
    "                # If yes each generation entry in the column will be devived by the amount of differenc EIC IDS and split into multiple Columns\n",
    "                amt_eic_ids = len(eic_ids_column)\n",
    "                if amt_eic_ids > 1:\n",
    "                    multiple_columns = True\n",
    "\n",
    "                # Use Try and Catch to handle multiple column names, as some Blocks are named different in seperate years\n",
    "                try:\n",
    "                    # Check if One column represents multiple EIC-IDs\n",
    "                    if multiple_columns:\n",
    "\n",
    "                        # Change Datatype of column\n",
    "                        smard_data_df[column_name] = pd.to_numeric(smard_data_df[column_name], errors=\"coerce\")\n",
    "\n",
    "                        # Create one new column per EIC-ID, where the EIC ID is the name\n",
    "                        for eic_id in eic_ids_column:\n",
    "                            \n",
    "                            # Each column get's the equal share of the Values, \n",
    "                            # so they're calculated by dividing the Values in the original column by the amount of EIC-IDs \n",
    "                            smard_data_df[eic_id] = smard_data_df[column_name] / len(eic_ids_column)\n",
    "                    else:\n",
    "                        # If it is just one EIC-ID for that column get the EIC-ID out of the eic_ids_column list\n",
    "                        eic_id = eic_ids_column[0]\n",
    "\n",
    "                        # Change Datatype of column to be able to use the pandas.sum() method\n",
    "                        smard_data_df[column_name] = pd.to_numeric(smard_data_df[column_name], errors=\"coerce\")\n",
    "\n",
    "                        # Rename the columns so the correct column will be changed to EIC-ID as Column name\n",
    "                        smard_data_df.columns = [eic_id if x== column_name else x for x in smard_data_df.columns]\n",
    "                \n",
    "                # Throws exception when column_name doesn't exist in thes smard_data_df\n",
    "                # Then try the second column name, if it exist. When this also fails, continue\n",
    "                except Exception as error:\n",
    "\n",
    "                    try:\n",
    "                        # Get second name of Column in csv File for that Block\n",
    "                        column_name = blocks_ets_df[blocks_ets_df[\"EIC\"] == eic_id][\"Column_Block_Smard_2\"].values[0]\n",
    "\n",
    "                        # Change Datatype of column to be able to use the pandas.sum() method\n",
    "                        smard_data_df[column_name] = pd.to_numeric(smard_data_df[column_name], errors=\"coerce\")\n",
    "                        \n",
    "                        # Rename the columns so the correct column will be changed to EIC-ID as Column name\n",
    "                        smard_data_df.columns = [eic_id if x == column_name else x for x in smard_data_df.columns]\n",
    "                    \n",
    "                    except Exception as error:\n",
    "                        print(error)\n",
    "                        print(f\"WARNING: Error for {bna_name} in year {year}\")\n",
    "                        continue\n",
    "                        \n",
    "\n",
    "            # Get all Columns containing Generation Data but not belonging to the defined Units with EIC-ID\n",
    "            column_drops = [column for column in smard_data_df.columns.values[3:] if column not in eic_ids]\n",
    "\n",
    "            # Delete the columns not having the correct EIC-IDs\n",
    "            # Use copy, because smard_data_df might be used again in the next loop, when multiple ETS-IDs exist\n",
    "            smard_data_df_output = smard_data_df.drop(column_drops, axis=1).copy()\n",
    "\n",
    "            # # Rename First 3 Columns so all are named the same\n",
    "            new_column_names = [\"date\", \"start\", \"end\"]\n",
    "            for i in range(3): smard_data_df_output.columns.values[i] = new_column_names[i]\n",
    "\n",
    "            # Get timestamp by date and time, where the timestamop defines the start time of the hourly generation data\n",
    "            smard_data_df_output[\"Timestamp\"] = smard_data_df_output.apply(lambda x: to_datetime(x), axis=1)\n",
    "\n",
    "            # Set timestamp as index\n",
    "            smard_data_df_output = smard_data_df_output.set_index([\"Timestamp\"])\n",
    "\n",
    "            # Drop the columns [\"date\", \"start\", \"end\"], because we just need the timestamp\n",
    "            smard_data_df_output = smard_data_df_output.drop(new_column_names, axis=1)\n",
    "\n",
    "            # Save as CSV file with the name pattern {plant_name}_{ets_id}_{year}.csv\n",
    "            smard_data_df_output.to_csv(f\"output/ets/{plant_name}_{ets_id}_{year}.csv\")\n",
    "            smard_data_df_output.to_excel(f\"output/ets/{plant_name}_{ets_id}_{year}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eaa80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
